# -*- coding: utf-8 -*-
"""Player_ReIdentification_Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D2jCXy_0Nf9uR2L3Fk2U5ihOpzrH_Z32
"""

from google.colab import files

uploaded = files.upload()  # ðŸ”¼ Upload `best.pt` and your test video file (like .mp4)

!pip install ultralytics --upgrade

from ultralytics import YOLO

# Load your model
model = YOLO("best.pt")

from google.colab import files

uploaded = files.upload()  # ðŸ”¼ Upload your test video (e.g., .mp4 file)

import os

print("Current directory files:")
print(os.listdir())

from ultralytics import YOLO
import cv2

# Load your trained model
model = YOLO("best.pt")

results = model.predict(source="855564-hd_1920_1080_24fps.mp4", save=True, conf=0.4)

print("âœ… Prediction complete. Output video saved in 'runs/predict/' folder.")

!ls runs/detect/

!ls runs/detect/predict

import os
import shutil

predict_root = "runs/detect"
if not os.path.exists(predict_root):
    raise FileNotFoundError("âŒ 'runs/detect' folder not found. Make sure detection was done.")

subfolders = sorted(
    [f.path for f in os.scandir(predict_root) if f.is_dir()],
    key=lambda x: os.path.getmtime(x),
    reverse=True
)
latest_folder = subfolders[0]
print("âœ… Latest prediction folder found at:", latest_folder)

video_files = [f for f in os.listdir(latest_folder) if f.endswith(".avi")]
copied = False
for video_file in video_files:
    src_path = os.path.join(latest_folder, video_file)
    dst_path = "output_result.avi"
    shutil.copy(src_path, dst_path)
    print("âœ… Copied:", video_file, "to", dst_path)
    copied = True

if not copied:
    raise FileNotFoundError("âŒ No .avi file found in the latest detect folder.")

import cv2
import os

video_path = "output_result.avi"
output_folder = "reid_frames"

if not os.path.exists(output_folder):
    os.makedirs(output_folder)

cap = cv2.VideoCapture(video_path)
frame_count = 0

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    frame_name = os.path.join(output_folder, f"frame_{frame_count:04d}.jpg")
    cv2.imwrite(frame_name, frame)
    frame_count += 1

cap.release()
print(f"âœ… Extracted {frame_count} frames to '{output_folder}' folder.")

from ultralytics import YOLO
import cv2
import os

model = YOLO("yolov8n.pt")
frames_folder = "reid_frames"
output_crop_folder = "player_crops"

if not os.path.exists(output_crop_folder):
    os.makedirs(output_crop_folder)

frame_files = sorted(os.listdir(frames_folder))
player_count = 0

for frame_file in frame_files:
    frame_path = os.path.join(frames_folder, frame_file)
    img = cv2.imread(frame_path)

    results = model(img)

    for result in results:
        boxes = result.boxes
        for box in boxes:
            cls = int(box.cls)
            if cls == 0:  # class 0 = person
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                crop = img[y1:y2, x1:x2]
                crop_filename = f"{output_crop_folder}/player_{player_count:05d}.jpg"
                cv2.imwrite(crop_filename, crop)
                player_count += 1

print(f"âœ… Extracted {player_count} player crops to '{output_crop_folder}' folder.")

import torch
import torchvision.models as models
from torchvision import transforms
from PIL import Image
import os
import numpy as np
from tqdm import tqdm

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# âœ… Load TorchVision EfficientNet-B0 and remove classifier
model = models.efficientnet_b0(pretrained=True)
model.classifier = torch.nn.Identity()
model.eval().to(device)

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

features = {}
crop_dir = 'player_crops'

for fname in tqdm(os.listdir(crop_dir)):
    if not fname.endswith('.jpg'):
        continue
    path = os.path.join(crop_dir, fname)
    image = Image.open(path).convert('RGB')
    input_tensor = transform(image).unsqueeze(0).to(device)

    with torch.no_grad():
        feat = model(input_tensor).cpu().numpy().flatten()

    features[fname] = feat

# Save features
np.save('player_features.npy', features)
print(f"âœ… Extracted features for {len(features)} players and saved to 'player_features.npy'")

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from collections import defaultdict
import os

# Load features
features = np.load('player_features.npy', allow_pickle=True).item()

# Convert
data = list(features.items())
filenames, vectors = zip(*data)
vectors = np.array(vectors)

# Calculate cosine similarity matrix
similarity_matrix = cosine_similarity(vectors)

# Threshold for similarity
threshold = 0.9

# Group
groups = defaultdict(list)
visited = set()
group_id = 0

for i in range(len(vectors)):
    if i in visited:
        continue
    groups[group_id].append(filenames[i])
    visited.add(i)
    for j in range(i + 1, len(vectors)):
        if j not in visited and similarity_matrix[i][j] > threshold:
            groups[group_id].append(filenames[j])
            visited.add(j)
    group_id += 1

# Save
with open("player_groups.txt", "w") as f:
    for gid, files in groups.items():
        f.write(f"Group {gid}:\n")
        for file in files:
            f.write(f"\t{file}\n")
        f.write("\n")

print(f"âœ… ReID done. Total unique players: {len(groups)}. Groups saved to 'player_groups.txt'")

import cv2
import os


group_file = "player_groups.txt"
id_map = {}

with open(group_file, "r") as f:
    gid = -1
    for line in f:
        if line.startswith("Group"):
            gid = int(line.strip().split()[1][:-1])
        elif line.strip():
            fname = line.strip()
            id_map[fname] = gid


video_path = "output_result.avi"
cap = cv2.VideoCapture(video_path)
fps = int(cap.get(cv2.CAP_PROP_FPS))
width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

out = cv2.VideoWriter("final_output.avi", cv2.VideoWriter_fourcc(*'XVID'), fps, (width, height))

frame_idx = 0
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Overlay IDs
    for fname, pid in id_map.items():
        if f"frame{frame_idx:04d}" in fname:
            x1, y1, x2, y2 = map(int, fname.split('_')[-4:])
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, f'ID: {pid}', (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

    out.write(frame)
    frame_idx += 1

cap.release()
out.release()

print("âœ… Final video saved as 'final_output.avi'")

from google.colab import files
files.download('final_output.avi')